{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice assignment: Handling categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dZEp05rN8tN"
   },
   "source": [
    "In this programming assignment, you are going to work with the following dataset from Kaggle:\n",
    "\n",
    "https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists\n",
    "\n",
    "This assignment is graded by your `submission.json`.\n",
    "\n",
    "The cell below creates a valid `submission.json` file, fill your answers in there. \n",
    "\n",
    "You can press \"Submit Assignment\" at any time to submit partial progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission.json\n"
     ]
    }
   ],
   "source": [
    "%%file submission.json\n",
    "{\n",
    "    \"q1\": 0,\n",
    "    \"q2\": 0,\n",
    "    \"q3\": 0,\n",
    "    \"q4\": 0,\n",
    "    \"q5\": 0,\n",
    "    \"q6\": 0,\n",
    "    \"q7\": 0,\n",
    "    \"q8\": 0,\n",
    "    \"q9\": 0,\n",
    "    \"q10\": 0,\n",
    "    \"q11\": 0,\n",
    "    \"q12\": 0,\n",
    "    \"q13\": 0,\n",
    "    \"q14\": 0,\n",
    "    \"q15\": 0,\n",
    "    \"q16\": \"\",\n",
    "    \"q17\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "Suppose that a company working with Big Data and Data Science wants to hire data scientists among people who have successfully passed some courses conducted by the company. Many people sign up for their training. The company wants to focus of the candidates who really want to work for them after training. Information related to demographics, education, experience is provided by the candidates via a sign-up form.\n",
    "\n",
    "This dataset is designed to understand the factors that lead a person to leave current job which is useful for HR researches. Based on the provided data, you are going to predict whether a candidate is looking for a job change.\n",
    "\n",
    "The whole data is divided into train and test parts. Data contains several categorical features – they need to be encoded.\n",
    "\n",
    "## Feature description\n",
    "\n",
    "- `enrollee_id`: Unique ID for a candidate\n",
    "- `city`: City code\n",
    "- `city_development_index`: Developement index of the city (scaled)\n",
    "- `gender`: Gender of a candidate\n",
    "- `relevent_experience`: Relevant experience of a candidate\n",
    "- `enrolled_university`: Type of University course enrolled in if any\n",
    "- `education_level`: Education level of a candidate\n",
    "- `major_discipline`: Education major discipline of a candidate\n",
    "- `experience`: Candidate total experience in years\n",
    "- `company_size`: Number of employees in a current employer's company\n",
    "- `company_type`: Type of a current employer\n",
    "- `last_new_job`: Difference in years between previous and current jobs\n",
    "- `training_hours`: training hours completed\n",
    "- `target`: 0 – Not looking for job change, 1 – Looking for a job change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-riW7UN88QB0"
   },
   "source": [
    "## 1\n",
    "\n",
    "Before modifying the features, let's study our dataframe a bit. First, call `.dtypes` for `train` dataframe. \n",
    "\n",
    "**q1:** How many columns in `train` contain data types different from numbers (ints and floats)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                 int64\n",
       "city                       object\n",
       "city_development_index    float64\n",
       "gender                     object\n",
       "relevent_experience        object\n",
       "enrolled_university        object\n",
       "education_level            object\n",
       "major_discipline           object\n",
       "experience                 object\n",
       "company_size               object\n",
       "company_type               object\n",
       "last_new_job               object\n",
       "training_hours              int64\n",
       "target                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TLmsIbke6RTE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>2</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Early Stage Startup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_71</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>Part time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_159</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city_16</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>city_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>city_103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>city_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>city_103</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>city_67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>14</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  gender      relevent_experience enrolled_university  \\\n",
       "0       city_16     NaN  Has relevent experience       no_enrollment   \n",
       "1       city_21     NaN   No relevent experience       no_enrollment   \n",
       "2       city_71    Male  Has relevent experience    Part time course   \n",
       "3      city_159    Male  Has relevent experience       no_enrollment   \n",
       "4       city_16    Male  Has relevent experience       no_enrollment   \n",
       "...         ...     ...                      ...                 ...   \n",
       "19153   city_16     NaN  Has relevent experience       no_enrollment   \n",
       "19154  city_103     NaN  Has relevent experience       no_enrollment   \n",
       "19155   city_11     NaN   No relevent experience    Full time course   \n",
       "19156  city_103    Male   No relevent experience       no_enrollment   \n",
       "19157   city_67  Female  Has relevent experience       no_enrollment   \n",
       "\n",
       "      education_level major_discipline experience company_size  \\\n",
       "0         High School              NaN         19      100-500   \n",
       "1             Masters             STEM          2        50-99   \n",
       "2            Graduate             STEM        >20          NaN   \n",
       "3             Masters             STEM        >20          <10   \n",
       "4             Masters             STEM          6          NaN   \n",
       "...               ...              ...        ...          ...   \n",
       "19153             NaN              NaN         11          NaN   \n",
       "19154        Graduate             STEM        >20          NaN   \n",
       "19155        Graduate             STEM         <1          NaN   \n",
       "19156        Graduate             STEM         15       10000+   \n",
       "19157        Graduate             STEM         14        50-99   \n",
       "\n",
       "              company_type last_new_job  \n",
       "0                  Pvt Ltd            2  \n",
       "1      Early Stage Startup            1  \n",
       "2                      NaN            2  \n",
       "3                  Pvt Ltd           >4  \n",
       "4                      NaN            4  \n",
       "...                    ...          ...  \n",
       "19153                  NaN            1  \n",
       "19154                  NaN           >4  \n",
       "19155                  NaN        never  \n",
       "19156              Pvt Ltd            2  \n",
       "19157              Pvt Ltd            2  \n",
       "\n",
       "[19158 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZmIR0DeNj-4"
   },
   "source": [
    "## 2\n",
    "\n",
    "**q2:** How many unique caterogies does a feature `'city'` contain in the train data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w1OFKy0S6SdX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['city'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT4YJ6DaOjF7"
   },
   "source": [
    "## 3\n",
    "\n",
    "**q3:** How many features in train data contain missing values (NaN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BaEwQjRg6Tj_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                    4508\n",
       "relevent_experience          0\n",
       "enrolled_university        386\n",
       "education_level            460\n",
       "major_discipline          2813\n",
       "experience                  65\n",
       "company_size              5938\n",
       "company_type              6140\n",
       "last_new_job               423\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxc_ZFXyQ2lc"
   },
   "source": [
    "## 4\n",
    "\n",
    "Some features have a relatively small number of missing values. For instance, `'experience'` has only 65 missing values in the train data. Replacing these missing values with a special category might introduce bias to the data. However, since the number of missing values is not so big, we might be OK with it.\n",
    "\n",
    "Replace missing values in `'experience'` feature with a category -1.\n",
    "\n",
    "**q4:** How many categories does this feature contain in the train data now?\n",
    "\n",
    "_(hint: you might want to use `fillna` function from `pandas` library in this task, but remember that it's not an in-place function by default. Or you can use `SimpleImputer` from `sklearn`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.experience.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.experience.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dWv8Npro6VA1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['experience'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od7G5iQ2ZVNB"
   },
   "source": [
    "## 5\n",
    "\n",
    "`'education_level'` is an example of an ordinal feature. Sure, we can define an order on it. For instance, `'High School'` is \"bigger\" than `'Primary School'`, and `'Phd'` is \"bigger\" than '`Graduate'`. We can encode this feature with integer numbers in a correct order.\n",
    "\n",
    "In this task, apply a correct mapping for the values of `'education_level'` feature. The mapping should be the following:\n",
    "\n",
    "* `'Primary School'` -> 0\n",
    "* `'High School'` -> 1\n",
    "* `'Graduate'` -> 2\n",
    "* `'Masters'` -> 3\n",
    "* `'Phd'` -> 4\n",
    "\n",
    "At the same time, impute missing values in `'education_level'` with a new category -1. So another part of the mapping would be:\n",
    "\n",
    "* `np.nan` -> -1\n",
    "\n",
    "**q5:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35).\n",
    "\n",
    "_(hint: you might want to use `map` function from `pandas` in this task)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BKDebpQX6WL7"
   },
   "outputs": [],
   "source": [
    "map_education = {\n",
    "    'Primary School': 0,\n",
    "    'High School': 1,\n",
    "    'Graduate': 2,\n",
    "    'Masters': 3,\n",
    "    'Phd': 4,\n",
    "    np.nan: -1\n",
    "}\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['education_level'] = train['education_level'].map(map_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['education_level'] = test['education_level'].map(map_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.061384278108362"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['education_level'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAi9S-YBrOlY"
   },
   "source": [
    "## 6\n",
    "\n",
    "Feature `'relevent_experience'` is an example of a binary feature. You can also check that it has no missing values, which makes its encoding pretty easy.\n",
    "\n",
    "Encode this feature with the following mapping:\n",
    "\n",
    "*   `\"No relevent experience\"` -> 0\n",
    "*   `\"Has relevent experience\"` -> 1\n",
    "\n",
    "**q6:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l5uTrVl36XjM"
   },
   "outputs": [],
   "source": [
    "map_relevent_experience =  {\"No relevent experience\": 0,\n",
    "\"Has relevent experience\": 1}\n",
    "train['relevent_experience'] = train['relevent_experience'].map(map_relevent_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['relevent_experience'] = test['relevent_experience'].map(map_relevent_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199081323728991"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['relevent_experience'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv-zgcIDtzqR"
   },
   "source": [
    "## 7\n",
    "\n",
    "In our case, `'gender'` is an example of a nominal feature (notice that it is not a binary feature cause it contains three categories + NaNs). We will use One-Hot encoding to encode it. There are several options how to do it in practice: for example, to use `get_dummies` function from `pandas` or `OneHotEncoder` from `sklearn.preprocessing`. Here, we will go with the first option.\n",
    "\n",
    "If you want to encode a whole dataset with One-Hot encoding, you can directly pass it into the discussed methods. But here we want to encode only one feature. We suggest to do it in four steps:\n",
    "\n",
    "1. Obtain a One-Hot encoding dataframe for the feature `'gender'`: apply `pd.get_dummies` to this feature. As a result, you should obtain a dataframe with three features (three different categories for gender). Don't include `'NaN'` feature - it will already be included as the encoding (0, 0, 0).\n",
    "2. Change the column names of this dataframe, so that a feature `'<category_name>'` will become `'gender-<category_name>'`. Of course, it is not a necessary step in general. However, it probably would be more convenient to work with a full dataframe if we remember that these One-Hot encoded features originally came from the feature `'gender'`. On a technical side, you can perform it by changing `df_gender.columns` list.\n",
    "3. Concatenate original and new dataframes. You can do it by calling `pd.concat` function. Don't forget to set `'axis'` parameter, so that you concatenate dataframes by columns, not by rows. As a result of this step, you should obtain a new `train` dataframe with three new columns named like `'gender-<category_name>'`.\n",
    "4. Finally, drop `'gender'` feature because we have already encoded it.\n",
    "\n",
    "As a result of these four steps, you should obtain a new version of `train` dataframe, with dropped `'gender'` feature and three new features named like `'gender-<category_name>'`. A total number of columns by this time should be equal to 16.\n",
    "\n",
    "**q7:** What is the total number of zero values which appear in the columns starting with `'gender-'`?\n",
    "\n",
    "_Example: suppose that you obtain the following dataframe:_\n",
    "\n",
    "| gender-category1 | gender-category2   | gender-category3|\n",
    "|------|------|------|\n",
    "|   0  | 1| 0|\n",
    "|0|0|0|\n",
    "\n",
    "_Then the answer for the question above should be 5._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7IGy0CV96Y8Q"
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train, pd.get_dummies(train['gender'], prefix='gender', prefix_sep='-')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='gender', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42824"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[['gender-Female', 'gender-Male',\n",
    "       'gender-Other'\n",
    "      ]] == 0).astype(int).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat((test, pd.get_dummies(test['gender'], prefix='gender', prefix_sep='-')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns='gender', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJx2G8ZQv_Hy"
   },
   "source": [
    "## 8\n",
    "\n",
    "Perform One-Hot encoding for the feature `'enrolled_university'`, using the similar procedure as in the previous task:\n",
    "\n",
    "1. Obtain a One-Hot encoding dataframe for `'enrolled_university'`.\n",
    "2. Rename its columns.\n",
    "3. Concatenate original and One-Hot encoding dataframes.\n",
    "4. Drop `'enrolled_university'` column.\n",
    "\n",
    "A total number of columns by this time should be equal to 18.\n",
    "\n",
    "**q8:** What is the total number of zero values which appear in the columns starting with `'enrolled_university-'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TrHkhli66aPP"
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train, pd.get_dummies(train['enrolled_university'], prefix='enrolled_university', prefix_sep='-')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat((test, pd.get_dummies(test['enrolled_university'], prefix='enrolled_university', prefix_sep='-')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='enrolled_university', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns='enrolled_university', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38702"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[[ 'enrolled_university-Full time course',\n",
    "       'enrolled_university-Part time course',\n",
    "       'enrolled_university-no_enrollment']] == 0).astype(int).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBervQFY9N7K"
   },
   "source": [
    "## 9\n",
    "\n",
    "Encode feature `'city'` using frequency encoding. You should map each category `'city_i'` to its count (a total number of observations in `train` with `city == 'city_i'`). Save this mapping, since later you would apply the same mapping to the test data.\n",
    "\n",
    "As a result of this task, feature `'city'` should be encoded with category counts in `train`. \n",
    "\n",
    "**q9:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Co-kiLuc6bO6"
   },
   "outputs": [],
   "source": [
    "map_city = train['city'].value_counts()\n",
    "train['city'] = train['city'].map(map_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['city'] = test['city'].map(map_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709.79643"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['city'].mean(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksJw_j-M9XCC"
   },
   "source": [
    "## 10\n",
    "\n",
    "Encode feature `'last_new_job'` with target encoding with no modifications. First, impute missing values in this feature with a new category `'-1'`. Then, map each category of `'last_new_job'` to the mean target value of the observations with the corresponding category. Save this mapping, since later you would apply the same mapping to the test data.\n",
    "\n",
    "**q10:** What will be the maximum value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.35).\n",
    "\n",
    "_(hint: you might want to use `groupby` function from `pandas` in this task)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['last_new_job'].fillna('-1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tmZgKA1_6caQ"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "map_last_new_job = train.groupby(['last_new_job'])['target'].mean()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['last_new_job'] = train['last_new_job'].map(map_last_new_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['last_new_job'].fillna('-1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['last_new_job'] = test['last_new_job'].map(map_last_new_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36407"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['last_new_job'].max(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyIVTPEY9eLb"
   },
   "source": [
    "## 11\n",
    "\n",
    "Encode feature `'experience'` with M-estimate encoding. Map each category of `'experience'` according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) + m\\times y_{\\text{mean}}}{\\text{count}\\left(j, x_{ij}\\right) + m}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $x_{ij}$ is a category being encoded,\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $m$ is a parameter.\n",
    "\n",
    "In this task, set $m = 0.5$. \n",
    "\n",
    "**q11:** What will be the maximum value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cbihpCuH6dxL"
   },
   "outputs": [],
   "source": [
    "m = 0.5\n",
    "map_experience = (train.groupby('experience')['target'].sum() + m * train['target'].mean()) / (train.groupby('experience')['target'].count() + m)\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['experience'] = train['experience'].map(map_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['experience'] = test['experience'].map(map_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45383"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['experience'].max(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0eCGRxLLJ-Y"
   },
   "source": [
    "## 12\n",
    "\n",
    "Encode feature `'major_discipline'` with Leave-One-Out encoding. Remember that this technique is similar to target encoding, but here while computing the encoding for a particular observation, we exclude it from the target encoding formula. Therefore a category $x_{ij}$ for the $i$-th observation will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) - y_i}{\\text{count}\\left(j, x_{ij}\\right) - 1}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $y_i$ is a target value of the $i$-th observation\n",
    "\n",
    "For example, suppose that you have the following train data:\n",
    "\n",
    "|feature|target|\n",
    "|-|-|\n",
    "|A|1|\n",
    "|A|0|\n",
    "|B|1|\n",
    "|B|0|\n",
    "|A|0|\n",
    "\n",
    "Then you obtain the following Leave-One-Out encoding:\n",
    "\n",
    "|feature|feature_loo_encoded|\n",
    "|-|-|\n",
    "|A|0.0|\n",
    "|A|0.5|\n",
    "|B|0.0|\n",
    "|B|1.0|\n",
    "|A|0.5|\n",
    "\n",
    "It is very important to notice that in this method the same category can be encoded differently for different observations. Thus, after encoding the train part of data, you should create a mapping which will help to encode the test data. In order to do this, simply average train encoding values within each category to obtain the final encoding. For instance, suppose that you obtain the following train dataframe:\n",
    "\n",
    "|feature|feature_loo_encoded|\n",
    "|-|-|\n",
    "|A|0.2|\n",
    "|A|0.6|\n",
    "|B|0.3|\n",
    "|B|0.7|\n",
    "|A|0.4|\n",
    "\n",
    "Then, for the test data, you should obtain the following mapping:\n",
    "\n",
    "* A -> 0.4 (because 0.4 is a mean value of the encoded values for the category A)\n",
    "* B -> 0.5 (because 0.5 is a mean value of the encoded values for the category B)\n",
    "\n",
    "Don't impute any missing values in this task. After completing this task, drop the feature `'major_discipline'` and rename `'major_discipline_loo_encoded'` to `'major_discipline'`.\n",
    "\n",
    "**q12:** What will be the maximum value of the encoding values for `'major_discipline'` for the TEST data in the mapping described above? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sV6QygUw6fcb"
   },
   "outputs": [],
   "source": [
    "train['major_discipline_loo_encoded'] = (train['major_discipline'].map(train.groupby(['major_discipline'])['target'].sum()) - train['target']) / (train['major_discipline'].map(train.groupby(['major_discipline'])['target'].count()) - 1)\n",
    "map_major_discipline = train.groupby('major_discipline')['major_discipline_loo_encoded'].mean()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['major_discipline_loo_encoded'] = test['major_discipline'].map(map_major_discipline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='major_discipline', inplace=True)\n",
    "train.rename(columns={'major_discipline_loo_encoded': 'major_discipline'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns='major_discipline', inplace=True)\n",
    "test.rename(columns={'major_discipline_loo_encoded': 'major_discipline'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26772"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test['major_discipline'].max(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQmH1y-d9qOW"
   },
   "source": [
    "## 13\n",
    "\n",
    "Encode feature `'company_size'` with Catboost encoding. The technique was described in the lecture. Here, for the sake of simplicity, let's use the implementation from `category_encoders` library.\n",
    "\n",
    "As you may remember, Catboost encoding depends on how the data is ordered. Normally, you should shuffle the data one time or even several times. In this task, we will assume that the data has already been shuffled, so you don't need to shuffle it again.\n",
    "\n",
    "Take `CatBoostEncoder` and use the default values for all its parameters, except `handle_missing` - set it to `'return_nan'` so that your encoder don't do anything with missing values. Fit it on the `'company_size'` (train data) and `'target'` and transform this feature. Save the encoder - it will be used later to transform this feature in test data.\n",
    "\n",
    "Don't impute any missing values in this task.\n",
    "\n",
    "**q13:** What will be the most popular value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (2.5.1.post0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from category_encoders) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
      "Requirement already satisfied: six in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\uladzislau_kisin\\anaconda\\envs\\datascrap\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "PfmCVKRx6hHl"
   },
   "outputs": [],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "cbe = CatBoostEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['company_size'] = cbe.fit_transform(train['company_size'], train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['company_size'] = cbe.transform(test['company_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.24935\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['company_size'].mode(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBE4sCLL9uV4"
   },
   "source": [
    "## 14\n",
    "\n",
    "Encode feature `'company_type'` with Weight of Evidence (WoE) encoding. A category $x_{ij}$ will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\ln\\left(\\frac{\\mathbb{P}\\left(x_{ij}\\mid y=1\\right)}{\\mathbb{P}\\left(x_{ij}\\mid y=0\\right)}\\right)\\quad.\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=1\\right) = \\frac{\\text{count}\\left(y=1\\mid x_{ij}\\right)}{\\text{count}\\left(y=1\\right)}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=0\\right) = \\frac{\\text{count}\\left(y=0\\mid x_{ij}\\right)}{\\text{count}\\left(y=0\\right)}\n",
    "$$\n",
    "\n",
    "The notation means the following:\n",
    "\n",
    "* $\\text{count}\\left(y=1\\mid x_{ij}\\right)$ denotes the number of observations with the category $x_{ij}$ where the target value is equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\mid x_{ij}\\right)$ denotes the same but for the target value $0$;\n",
    "* $\\text{count}\\left(y=1\\right)$ denotes the number of observations with the target value equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\right)$ denotes the same but for the target value $0$.\n",
    "\n",
    "\n",
    "For example, suppose that you have the following train data:\n",
    "\n",
    "|feature|target|\n",
    "|-|-|\n",
    "|A|1|\n",
    "|A|0|\n",
    "|B|1|\n",
    "|B|0|\n",
    "|A|0|\n",
    "\n",
    "Then you obtain the following WoE encoding mapping:\n",
    "\n",
    "* A -> $\\ln\\left(\\frac{\\frac{1}{2}}{\\frac{2}{3}}\\right) \\approx -0.288$ \n",
    "* B -> $\\ln\\left(\\frac{\\frac{1}{2}}{\\frac{1}{3}}\\right) \\approx 0.405$ \n",
    "\n",
    "Don't impute any missing values in this task.\n",
    "\n",
    "**q14:** What will be the most popular value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = train.groupby(['company_type', 'target'], as_index=False)['enrollee_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter['target_sep'] = inter['target'].map(train.groupby('target')['enrollee_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter['p'] = inter['enrollee_id'] / inter['target_sep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "A52TWXmH6igK"
   },
   "outputs": [],
   "source": [
    "map_company_type = np.log(inter.query('target == 1')[['company_type', 'p']].set_index('company_type') / inter.query('target == 0')[['company_type', 'p']].set_index('company_type')).to_dict()['p']\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['company_type'] = train['company_type'].map(map_company_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['company_type'] = test['company_type'].map(map_company_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.40878\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['company_type'].mode(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFwADkfU9wxD"
   },
   "source": [
    "## 15\n",
    "\n",
    "We have encoded all categorical features. Next, we drop `'enrollee_id'` because it is not a representative feature. After this, we split train part of data into the dataframe which contains only features (without target) and the target array.\n",
    "\n",
    "Before training the models, we should impute the remaining missing values. You might have noticed that we didn't impute missing values for the features `'major_discipline'`, `'company_size'` and `'company_type'`. This is because the number of missing values in these features is relatively big (you can check it yourself). In practice, you might just create a special category (like `'-1'`) for each of these features before the encoding. However, in this task, let's perform the imputation using KNN approach - where we impute missing values by looking at the similar observations.\n",
    "\n",
    "Import `KNNImputer` from `sklearn`. It works only with the dataset with numbers - this is why we didn't run it before the encoding. Set `n_neighbors=3`, and let other parameters have the default values. Fit it on the train dataframe with features, and then transform it. Notice that after the transformation we will obtain `numpy.array` - make `pandas.DataFrame` out of it with the same columns as before.\n",
    "\n",
    "Save the KNN imputer - you will need it to process the test data. Check that there are no missing values in the train data anymore.\n",
    "\n",
    "**q15:** What is the mean value of the `'company_size'` feature in the train data after the imputation? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1610996515882,
     "user": {
      "displayName": "Evgeny Kovalev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapCcPAzYLJE2xqpH7xgS8qtR8bZrkCgbHm27oLg=s64",
      "userId": "07828702499945486090"
     },
     "user_tz": -180
    },
    "id": "eCz_Pr_xoa82",
    "outputId": "1457ef28-3783-488e-ea52-fc79f2e6f893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19158, 16), (19158,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "YvfwLqvS6kKr"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(data=imputer.fit_transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>gender-Female</th>\n",
       "      <th>gender-Male</th>\n",
       "      <th>gender-Other</th>\n",
       "      <th>enrolled_university-Full time course</th>\n",
       "      <th>enrolled_university-Part time course</th>\n",
       "      <th>enrolled_university-no_enrollment</th>\n",
       "      <th>major_discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1533</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174465</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2702</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.075476</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1533</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282059</td>\n",
       "      <td>0.624674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221574</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>1533</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.227426</td>\n",
       "      <td>0.405871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>4355</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.405802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>247</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.453827</td>\n",
       "      <td>0.405903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301387</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>4355</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166241</td>\n",
       "      <td>0.190317</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>431</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.182651</td>\n",
       "      <td>0.176857</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  city_development_index  relevent_experience  education_level  \\\n",
       "0      1533                   0.910                    1                1   \n",
       "1      2702                   0.624                    0                3   \n",
       "2       266                   0.884                    1                2   \n",
       "3        94                   0.843                    1                3   \n",
       "4      1533                   0.910                    1                3   \n",
       "...     ...                     ...                  ...              ...   \n",
       "19153  1533                   0.910                    1               -1   \n",
       "19154  4355                   0.920                    1                2   \n",
       "19155   247                   0.550                    0                2   \n",
       "19156  4355                   0.920                    0                2   \n",
       "19157   431                   0.855                    1                2   \n",
       "\n",
       "       experience  company_size  company_type  last_new_job  training_hours  \\\n",
       "0        0.174465      0.249348     -0.408782      0.241379              20   \n",
       "1        0.331818      0.249348     -0.075476      0.264303              10   \n",
       "2        0.153088      0.249348           NaN      0.241379               6   \n",
       "3        0.153088      0.249348     -0.408782      0.182371              56   \n",
       "4        0.282059      0.624674           NaN      0.221574              15   \n",
       "...           ...           ...           ...           ...             ...   \n",
       "19153    0.227426      0.405871           NaN      0.264303               4   \n",
       "19154    0.153088      0.405802           NaN      0.182371              56   \n",
       "19155    0.453827      0.405903           NaN      0.301387              12   \n",
       "19156    0.166241      0.190317     -0.408782      0.241379              16   \n",
       "19157    0.182651      0.176857     -0.408782      0.241379              72   \n",
       "\n",
       "       gender-Female  gender-Male  gender-Other  \\\n",
       "0                  0            0             0   \n",
       "1                  0            0             0   \n",
       "2                  0            1             0   \n",
       "3                  0            1             0   \n",
       "4                  0            1             0   \n",
       "...              ...          ...           ...   \n",
       "19153              0            0             0   \n",
       "19154              0            0             0   \n",
       "19155              0            0             0   \n",
       "19156              0            1             0   \n",
       "19157              1            0             0   \n",
       "\n",
       "       enrolled_university-Full time course  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "19153                                     0   \n",
       "19154                                     0   \n",
       "19155                                     1   \n",
       "19156                                     0   \n",
       "19157                                     0   \n",
       "\n",
       "       enrolled_university-Part time course  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "19153                                     0   \n",
       "19154                                     0   \n",
       "19155                                     0   \n",
       "19156                                     0   \n",
       "19157                                     0   \n",
       "\n",
       "       enrolled_university-no_enrollment  major_discipline  \n",
       "0                                      1               NaN  \n",
       "1                                      1          0.261542  \n",
       "2                                      0          0.261542  \n",
       "3                                      1          0.261611  \n",
       "4                                      1          0.261611  \n",
       "...                                  ...               ...  \n",
       "19153                                  1               NaN  \n",
       "19154                                  1          0.261542  \n",
       "19155                                  0          0.261611  \n",
       "19156                                  1          0.261542  \n",
       "19157                                  1          0.261611  \n",
       "\n",
       "[19158 rows x 16 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>gender-Female</th>\n",
       "      <th>gender-Male</th>\n",
       "      <th>gender-Other</th>\n",
       "      <th>enrolled_university-Full time course</th>\n",
       "      <th>enrolled_university-Part time course</th>\n",
       "      <th>enrolled_university-no_enrollment</th>\n",
       "      <th>major_discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174465</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2702.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.075476</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.429107</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.282059</td>\n",
       "      <td>0.624674</td>\n",
       "      <td>-0.297680</td>\n",
       "      <td>0.221574</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.227426</td>\n",
       "      <td>0.405871</td>\n",
       "      <td>-0.327249</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>4355.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.405802</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>247.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.453827</td>\n",
       "      <td>0.405903</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.301387</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>4355.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166241</td>\n",
       "      <td>0.190317</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>431.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.182651</td>\n",
       "      <td>0.176857</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  city_development_index  relevent_experience  education_level  \\\n",
       "0      1533.0                   0.910                  1.0              1.0   \n",
       "1      2702.0                   0.624                  0.0              3.0   \n",
       "2       266.0                   0.884                  1.0              2.0   \n",
       "3        94.0                   0.843                  1.0              3.0   \n",
       "4      1533.0                   0.910                  1.0              3.0   \n",
       "...       ...                     ...                  ...              ...   \n",
       "19153  1533.0                   0.910                  1.0             -1.0   \n",
       "19154  4355.0                   0.920                  1.0              2.0   \n",
       "19155   247.0                   0.550                  0.0              2.0   \n",
       "19156  4355.0                   0.920                  0.0              2.0   \n",
       "19157   431.0                   0.855                  1.0              2.0   \n",
       "\n",
       "       experience  company_size  company_type  last_new_job  training_hours  \\\n",
       "0        0.174465      0.249348     -0.408782      0.241379            20.0   \n",
       "1        0.331818      0.249348     -0.075476      0.264303            10.0   \n",
       "2        0.153088      0.249348     -0.429107      0.241379             6.0   \n",
       "3        0.153088      0.249348     -0.408782      0.182371            56.0   \n",
       "4        0.282059      0.624674     -0.297680      0.221574            15.0   \n",
       "...           ...           ...           ...           ...             ...   \n",
       "19153    0.227426      0.405871     -0.327249      0.264303             4.0   \n",
       "19154    0.153088      0.405802     -0.408782      0.182371            56.0   \n",
       "19155    0.453827      0.405903     -0.408782      0.301387            12.0   \n",
       "19156    0.166241      0.190317     -0.408782      0.241379            16.0   \n",
       "19157    0.182651      0.176857     -0.408782      0.241379            72.0   \n",
       "\n",
       "       gender-Female  gender-Male  gender-Other  \\\n",
       "0                0.0          0.0           0.0   \n",
       "1                0.0          0.0           0.0   \n",
       "2                0.0          1.0           0.0   \n",
       "3                0.0          1.0           0.0   \n",
       "4                0.0          1.0           0.0   \n",
       "...              ...          ...           ...   \n",
       "19153            0.0          0.0           0.0   \n",
       "19154            0.0          0.0           0.0   \n",
       "19155            0.0          0.0           0.0   \n",
       "19156            0.0          1.0           0.0   \n",
       "19157            1.0          0.0           0.0   \n",
       "\n",
       "       enrolled_university-Full time course  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19153                                   0.0   \n",
       "19154                                   0.0   \n",
       "19155                                   1.0   \n",
       "19156                                   0.0   \n",
       "19157                                   0.0   \n",
       "\n",
       "       enrolled_university-Part time course  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       1.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19153                                   0.0   \n",
       "19154                                   0.0   \n",
       "19155                                   0.0   \n",
       "19156                                   0.0   \n",
       "19157                                   0.0   \n",
       "\n",
       "       enrolled_university-no_enrollment  major_discipline  \n",
       "0                                    1.0          0.261611  \n",
       "1                                    1.0          0.261542  \n",
       "2                                    0.0          0.261542  \n",
       "3                                    1.0          0.261611  \n",
       "4                                    1.0          0.261611  \n",
       "...                                  ...               ...  \n",
       "19153                                1.0          0.261611  \n",
       "19154                                1.0          0.261542  \n",
       "19155                                0.0          0.261611  \n",
       "19156                                1.0          0.261542  \n",
       "19157                                1.0          0.261611  \n",
       "\n",
       "[19158 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25282"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train_data['company_size'].mean(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2T2a78d90mJ"
   },
   "source": [
    "## 16\n",
    "\n",
    "Finally, train a Random Forest classifier from `sklearn` on the train data. Set `n_estimators=500`, `max_depth=8`, `random_state=13`, and let other parameters have the default values. Check feature importances. \n",
    "\n",
    "**q16:** What is the name of the most important feature for this model? Provide the name of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "g4_1694F6l0Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=8, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=500, random_state=13)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'major_discipline'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_names_in_[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUydmtoi92d8"
   },
   "source": [
    "## 17\n",
    "\n",
    "In this last task, process the test data so that it is possible to make Random Forest predictions on for it. Perform the similar operations as for the train data, but remember that now you work with test observations and therefore all operations are in the inference mode.\n",
    "\n",
    "1. (task 4) Feature `'experience'`: impute missing values by -1. \n",
    "2. (task 5) Feature `'education_level'`: perform ordinal encoding mapping.\n",
    "3. (task 6) Feature `'relevent_experience'`: perform binary mapping.\n",
    "4. (task 7) Feature `'gender'`: perform One-Hot encoding and obtain three new features starting with `'gender-'`. Drop `'gender'` feature.\n",
    "5. (task 8) Feature `'enrolled_university'`: perform One-Hot encoding and obtain three new features starting with `'enrolled_university-'`. Drop `'enrolled_university'` feature.\n",
    "6. (task 9) Feature `'city'`: perform frequency encoding mapping.\n",
    "7. (task 10) Feature `'last_new_job'`: impute missing values by -1 and perform target encoding mapping.\n",
    "8. (task 11) Feature `'experience'`: perform M-estimate encoding mapping.\n",
    "9. (task 12) Feature `'major_discipline'`: perform Leave-One-Out encoding mapping.\n",
    "10. (task 13) Feature `'company_size'`: perform Catboost encoding mapping.\n",
    "11. (task 14) Feature `'company_type'`: perform WoE encoding mapping.\n",
    "12. (task 15) Split `test` into `X_test` (a dataframe with no `'enrollee_id'` and `'target'`) and `y_test` (an array with target values). Impute missing values by using KNN imputer which you used before (now only in a transform mode).\n",
    "\n",
    "As a result of the operations described above, you should obtain `X_test` which is a `pandas.DataFrame` with a shape (2129, 16). Calculate the predictions of the trained Random Forest model on it. Check the accuracy of the predictions on test data.\n",
    "\n",
    "Then calculate the predictions of the same model on `X_train` and check the accuracy there. Compare the accuracies on train and test data. Do you notice something? What, in your opinion, caused such difference in the accuracies?\n",
    "\n",
    "**q17:** As a result of this task, provide the accuracy for the test data, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "veC-y23Fwe8L"
   },
   "outputs": [],
   "source": [
    "X_test = test.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(data=imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1610996545175,
     "user": {
      "displayName": "Evgeny Kovalev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapCcPAzYLJE2xqpH7xgS8qtR8bZrkCgbHm27oLg=s64",
      "userId": "07828702499945486090"
     },
     "user_tz": -180
    },
    "id": "4kK-7S1Q16lp",
    "outputId": "b5b5ea5a-e883-4349-b9d8-fe0c91eae5a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2129, 16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "yM1CI29I6rv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7332080789102865"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, rf.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO77HBmz1/PpQ55VCcYPEhx",
   "collapsed_sections": [],
   "name": "Week1_practice.ipynb",
   "provenance": [
    {
     "file_id": "1WztG2ZwKA0bx5LJIEQNQH23OULDBBmt8",
     "timestamp": 1610996564372
    }
   ]
  },
  "coursera": {
   "schema_names": [
    "categorical-data-task-week-1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
